# -*- coding: utf-8 -*-
"""Pomogrante_output (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bMxyXGM0nJkseb77_CuAYo1pgfxzJ2Kf

import dataset
"""

from google.colab import drive
drive.mount('/content/drive')

"""display"""

import matplotlib.pyplot as plt
import cv2
import os
!pip install patool
import patoolib

# This is likely the directory containing the extracted files.
data_dir = "/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset"
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']

# Unrar the file if the directory doesn't exist
if not os.path.exists(data_dir):
    patoolib.extract_archive("/content/drive/MyDrive/Pomegranate Diseases Dataset.rar", outdir="/content/drive/MyDrive")


def load_and_display_images(data_dir, categories, num_images=5):
    plt.figure(figsize=(15, 15))

    image_count = 1  # Counter to keep track of the subplot index

    # Loop through each category
    for category in categories:
        path = os.path.join(data_dir, category)  # Get the path for each class
        images = os.listdir(path)  # List all images in the category

        # Display up to 'num_images' images from each category
        for i in range(num_images):
            img_path = os.path.join(path, images[i])  # Get the path of the image
            image = cv2.imread(img_path)  # Read the image using OpenCV
            if image is not None:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR (OpenCV) to RGB (matplotlib)

                # Plot the image
                plt.subplot(len(categories), num_images, image_count)  # Set subplot position
                plt.imshow(image)  # Display the image
                plt.title(category)  # Set the title as the category name
                plt.axis('off')  # Turn off the axis labels
                image_count += 1  # Increment the counter for the next subplot

    plt.tight_layout()
    plt.show()

# Call the function to display images
load_and_display_images(data_dir, categories)

"""data pre-processing"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Define the dataset directory and target size for resizing
data_dir = '/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset'
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']
target_size = (128, 128)

# Function to apply Gaussian filter
def apply_gaussian_filter(image):
    return cv2.GaussianBlur(image, (5, 5), 0)

# Function to resize image
def resize_image(image, size=(128, 128)):
    return cv2.resize(image, size)

# Function to enhance images using histogram equalization
def enhance_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    equalized = cv2.equalizeHist(gray)
    return cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)

# Function to convert image to grayscale
def convert_to_grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Function to convert image to binary
def convert_to_binary(image):
    _, binary = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    return binary

# Function to apply K-means clustering for segmentation
def apply_kmeans(image, k=4):
    Z = image.reshape((-1, 3))
    Z = np.float32(Z)
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
    ret, label, center = cv2.kmeans(Z, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
    center = np.uint8(center)
    res = center[label.flatten()]
    segmented_image = res.reshape((image.shape))
    return segmented_image

# Function to preprocess images and display results
def extract_and_display_features(data_dir, categories, target_size, images_per_class=10):
    for category in categories:
        category_path = os.path.join(data_dir, category)
        print(f"Displaying images from category: {category}")

        image_count = 0  # To track the number of images processed per category

        # Iterate through each image in the category folder
        for img_name in os.listdir(category_path):
            if image_count >= images_per_class:
                break  # Stop after displaying 10 images per category

            img_path = os.path.join(category_path, img_name)
            image = cv2.imread(img_path)

            if image is not None:
                # Resize the image
                image = cv2.resize(image, target_size)
                original_image = image.copy()  # Save the original image for comparison

                # Apply Gaussian filter
                gaussian_image = apply_gaussian_filter(image)

                # Convert the image to grayscale
                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

                # Enhance image
                enhanced_image = enhance_image(image)

                # Binary conversion
                binary_image = convert_to_binary(gray_image)

                # K-means segmentation
                kmeans_image = apply_kmeans(image)

                # Display original and each processed image
                def display_comparison(title, proc_image):
                    plt.figure(figsize=(10, 5))
                    plt.subplot(1, 2, 1)
                    plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
                    plt.title(f"Original - {category}")
                    plt.axis('off')
                    plt.subplot(1, 2, 2)
                    plt.imshow(proc_image, cmap='gray' if len(proc_image.shape) == 2 else None)
                    plt.title(title)
                    plt.axis('off')
                    plt.show()

                display_comparison("Gaussian Filter", gaussian_image)
                display_comparison("Resized Image", image)
                display_comparison("Enhanced Image", enhanced_image)
                display_comparison("Grayscale Image", gray_image)
                display_comparison("Binary Image", binary_image)
                display_comparison("K-means Segmentation", kmeans_image)

                image_count += 1  # Increment image count
            else:
                print(f'Failed to process image: {img_path}')

# Call the function to display images and their features
extract_and_display_features(data_dir, categories, target_size, images_per_class=10)

"""hog visualization"""

import os
import cv2
import numpy as np
from skimage.feature import hog
import matplotlib.pyplot as plt

# Define the dataset directory and target size for resizing
data_dir = '/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset'  # Path to your dataset
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']  # Categories in the dataset
target_size = (128, 128)  # Resize all images to 128x128

# Function to preprocess images and extract HOG features
def extract_and_display_hog_images(data_dir, categories, target_size, images_per_class=10):
    for category in categories:
        category_path = os.path.join(data_dir, category)
        print(f"Displaying images from category: {category}")

        image_count = 0  # To track the number of images processed per category

        # Iterate through each image in the category folder
        for img_name in os.listdir(category_path):
            if image_count >= images_per_class:
                break  # Stop after displaying 10 images per category

            img_path = os.path.join(category_path, img_name)
            image = cv2.imread(img_path)

            if image is not None:
                # Resize the image
                image = cv2.resize(image, target_size)

                # Convert the image to grayscale (HOG works on grayscale images)
                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

                # Extract HOG features and HOG visualization
                hog_feature, hog_image = hog(
                    gray_image,
                    orientations=9,
                    pixels_per_cell=(8, 8),
                    cells_per_block=(2, 2),
                    block_norm='L2-Hys',
                    visualize=True,
                    feature_vector=True
                )

                # Display the original and HOG image
                plt.figure(figsize=(8, 4))
                plt.subplot(1, 2, 1)
                plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
                plt.title(f"Original - {category}")
                plt.axis('off')

                plt.subplot(1, 2, 2)
                plt.imshow(hog_image, cmap='gray')
                plt.title("HOG Visualization")
                plt.axis('off')

                plt.show()

                image_count += 1  # Increment image count
            else:
                print(f'Failed to process image: {img_path}')

# Call the function to display 10 images and HOG visualizations per class
extract_and_display_hog_images(data_dir, categories, target_size, images_per_class=10)

"""gray scale images"""

import os
import cv2
import numpy as np
import pandas as pd
from skimage.feature import graycomatrix, graycoprops
import matplotlib.pyplot as plt

# Define the dataset directory and target size for resizing
data_dir = '/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset'
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']
target_size = (128, 128)

def resize_image(image, size=(128, 128)):
    return cv2.resize(image, size)

# Function to convert image to grayscale
def convert_to_grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Function to extract texture features using GLCM
def extract_texture_features(image):
    gray = convert_to_grayscale(image)
    glcm = graycomatrix(gray, distances=[1], angles=[0], symmetric=True, normed=True)
    features = {
        'contrast': graycoprops(glcm, 'contrast')[0, 0],
        'correlation': graycoprops(glcm, 'correlation')[0, 0],
        'energy': graycoprops(glcm, 'energy')[0, 0],
        'entropy': -np.sum(glcm * np.log2(glcm + (glcm == 0))),
        'homogeneity': graycoprops(glcm, 'homogeneity')[0, 0]
    }
    return features

# Function to preprocess images and extract/display texture features
def extract_and_display_texture_features(data_dir, categories, target_size, images_per_class=10):
    feature_data = []
    for category in categories:
        category_path = os.path.join(data_dir, category)
        print(f"Extracting features from category: {category}")

        image_count = 0  # To track the number of images processed per category

        # Iterate through each image in the category folder
        for img_name in os.listdir(category_path):
            if image_count >= images_per_class:
                break  # Stop after displaying 10 images per category

            img_path = os.path.join(category_path, img_name)
            image = cv2.imread(img_path)

            if image is not None:
                # Resize the image
                image = cv2.resize(image, target_size)
                original_image = image.copy()  # Save the original image for comparison

                # Extract texture features
                texture_features = extract_texture_features(image)

                # Display original and grayscale image
                gray_image = convert_to_grayscale(image)
                plt.figure(figsize=(10, 5))
                plt.subplot(1, 2, 1)
                plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
                plt.title(f"Original - {category}")
                plt.axis('off')
                plt.subplot(1, 2, 2)
                plt.imshow(gray_image, cmap='gray')
                plt.title("Grayscale Image")
                plt.axis('off')
                plt.show()

                # Store feature data
                feature_data.append({
                    'image': img_name,
                    'category': category,
                    **texture_features,
                })

                # Display texture feature values
                print(f"Image: {img_name}, Category: {category}")
                for feature, value in texture_features.items():
                    print(f"{feature}: {value}")
                print("-----")

                image_count += 1  # Increment image count
            else:
                print(f'Failed to process image: {img_path}')

    # Display the feature values in a DataFrame
    feature_df = pd.DataFrame(feature_data)
    print(feature_df)

# Call the function to extract and display texture features
extract_and_display_texture_features(data_dir, categories, target_size, images_per_class=10)

"""texture features"""

import os
import cv2
import numpy as np
import pandas as pd
from skimage.feature import graycomatrix, graycoprops

# Define the dataset directory and target size for resizing
data_dir = '/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset'
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']
target_size = (128, 128)

def resize_image(image, size=(128, 128)):
    return cv2.resize(image, size)

# Function to convert image to grayscale
def convert_to_grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Function to extract texture features using GLCM
def extract_texture_features(image):
    gray = convert_to_grayscale(image)
    glcm = graycomatrix(gray, distances=[1], angles=[0], symmetric=True, normed=True)
    features = {
        'contrast': graycoprops(glcm, 'contrast')[0, 0],
        'correlation': graycoprops(glcm, 'correlation')[0, 0],
        'energy': graycoprops(glcm, 'energy')[0, 0],
        'entropy': -np.sum(glcm * np.log2(glcm + (glcm == 0))),
        'homogeneity': graycoprops(glcm, 'homogeneity')[0, 0]
    }
    return features

# Function to preprocess images and calculate total values for texture features per category
def calculate_total_values_per_category(data_dir, categories, target_size):
    total_values_per_category = {category: {'contrast': 0, 'correlation': 0, 'energy': 0, 'entropy': 0, 'homogeneity': 0} for category in categories}
    for category in categories:
        category_path = os.path.join(data_dir, category)
        print(f"Processing category: {category}")

        # Iterate through each image in the category folder
        for img_name in os.listdir(category_path):
            img_path = os.path.join(category_path, img_name)
            image = cv2.imread(img_path)

            if image is not None:
                # Resize the image
                image = cv2.resize(image, target_size)

                # Extract texture features
                texture_features = extract_texture_features(image)

                # Sum up the texture feature values for the current category
                for feature, value in texture_features.items():
                    total_values_per_category[category][feature] += value
            else:
                print(f'Failed to process image: {img_path}')

    return total_values_per_category

# Calculate total values for the texture features per category
total_values_per_category = calculate_total_values_per_category(data_dir, categories, target_size)
print("Total values for texture features per category:")
for category, features in total_values_per_category.items():
    print(f"Category: {category}")
    for feature, value in features.items():
        print(f"{feature}: {value}")
    print("-----")

"""color features"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Define the dataset directory and target size for resizing
data_dir = '/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset'
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']
target_size = (128, 128)

def resize_image(image, size=(128, 128)):
    return cv2.resize(image, size)

# Function to extract color features
def extract_color_features(image):
    channels = cv2.meanStdDev(image)
    mean = channels[0].flatten()
    std_dev = channels[1].flatten()
    kurtosis = cv2.mean(cv2.pow(image - mean, 4))[0] / cv2.mean(cv2.pow(image - mean, 2))[0]**2 - 3
    skewness = cv2.mean(cv2.pow(image - mean, 3))[0] / cv2.mean(cv2.pow(image - mean, 2))[0]**1.5
    features = {
        'mean': mean.tolist(),
        'std_dev': std_dev.tolist(),
        'kurtosis': kurtosis,
        'skewness': skewness
    }
    return features

# Function to preprocess images and extract/display color features
def extract_and_display_color_features(data_dir, categories, target_size, images_per_class=10):
    feature_data = []
    for category in categories:
        category_path = os.path.join(data_dir, category)
        print(f"Extracting features from category: {category}")

        image_count = 0  # To track the number of images processed per category

        # Iterate through each image in the category folder
        for img_name in os.listdir(category_path):
            if image_count >= images_per_class:
                break  # Stop after displaying 10 images per category

            img_path = os.path.join(category_path, img_name)
            image = cv2.imread(img_path)

            if image is not None:
                # Resize the image
                image = cv2.resize(image, target_size)
                original_image = image.copy()  # Save the original image for comparison

                # Extract color features
                color_features = extract_color_features(image)

                # Display original image
                plt.figure(figsize=(5, 5))
                plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
                plt.title(f"Original - {category}")
                plt.axis('off')
                plt.show()

                # Display color feature values
                print(f"Image: {img_name}, Category: {category}")
                for feature, value in color_features.items():
                    print(f"{feature}: {value}")
                print("-----")

                # Store feature data
                feature_data.append({
                    'image': img_name,
                    'category': category,
                    **color_features,
                })

                image_count += 1  # Increment image count
            else:
                print(f'Failed to process image: {img_path}')

    # Display the feature values in a DataFrame
    feature_df = pd.DataFrame(feature_data)
    print(feature_df)

# Call the function to extract and display color features
extract_and_display_color_features(data_dir, categories, target_size, images_per_class=10)

import os
import cv2
import numpy as np
import pandas as pd

# Define the dataset directory and target size for resizing
data_dir = '/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset'
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']
target_size = (128, 128)

def resize_image(image, size=(128, 128)):
    return cv2.resize(image, size)

# Function to extract color features
def extract_color_features(image):
    channels = cv2.meanStdDev(image)
    mean = channels[0].flatten()
    std_dev = channels[1].flatten()
    kurtosis = cv2.mean(cv2.pow(image - mean, 4))[0] / cv2.mean(cv2.pow(image - mean, 2))[0]**2 - 3
    skewness = cv2.mean(cv2.pow(image - mean, 3))[0] / cv2.mean(cv2.pow(image - mean, 2))[0]**1.5
    features = {
        'mean': mean.tolist(),
        'std_dev': std_dev.tolist(),
        'kurtosis': kurtosis,
        'skewness': skewness
    }
    return features

# Function to preprocess images and calculate total values for color features per category
def calculate_total_values_per_category(data_dir, categories, target_size):
    total_values_per_category = {category: {'mean': [0, 0, 0], 'std_dev': [0, 0, 0], 'kurtosis': 0, 'skewness': 0} for category in categories}
    for category in categories:
        category_path = os.path.join(data_dir, category)
        print(f"Processing category: {category}")

        # Iterate through each image in the category folder
        for img_name in os.listdir(category_path):
            img_path = os.path.join(category_path, img_name)
            image = cv2.imread(img_path)

            if image is not None:
                # Resize the image
                image = cv2.resize(image, target_size)

                # Extract color features
                color_features = extract_color_features(image)

                # Sum up the color feature values for the current category
                for feature, value in color_features.items():
                    if isinstance(value, list):
                        total_values_per_category[category][feature] = [sum(x) for x in zip(total_values_per_category[category][feature], value)]
                    else:
                        total_values_per_category[category][feature] += value
            else:
                print(f'Failed to process image: {img_path}')

    return total_values_per_category

# Calculate total values for the color features per category
total_values_per_category = calculate_total_values_per_category(data_dir, categories, target_size)
print("Total values for color features per category:")
for category, features in total_values_per_category.items():
    print(f"Category: {category}")
    for feature, value in features.items():
        print(f"{feature}: {value}")
    print("-----")

"""extracting"""

def extract_contour_features(image):
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Assuming the largest contour is the object of interest
    if contours:
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        perimeter = cv2.arcLength(largest_contour, True)
        return area, perimeter
    return 0, 0

# Example usage
for category in categories:
    category_path = os.path.join(data_dir, category)
    for img_name in os.listdir(category_path):
        img_path = os.path.join(category_path, img_name)
        image = cv2.imread(img_path)
        if image is not None:
            contour_features = extract_contour_features(image)
            print(f'Contour Features for {img_name}: {contour_features}')

"""**SVM classifier**"""

import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.svm import SVC
import matplotlib.pyplot as plt
import seaborn as sns

# Set dataset directory and categories
data_dir = '/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset'  # Path to your dataset
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']
target_size = (128, 128)  # Resize images to a uniform size

# Function to preprocess and flatten images
def preprocess_images(data_dir, categories, target_size):
    images = []
    labels = []

    for category in categories:
        category_path = os.path.join(data_dir, category)
        label = category  # Use category names as labels

        # Iterate through each image in the category folder
        for img_name in os.listdir(category_path):
            img_path = os.path.join(category_path, img_name)
            image = cv2.imread(img_path)
            if image is not None:
                # Resize image to target size
                image = cv2.resize(image, target_size)
                # Flatten the image into a 1D array
                image = image.flatten()
                # Normalize pixel values to [0, 1]
                image = image.astype('float32') / 255.0
                # Append image and label
                images.append(image)
                labels.append(label)
            else:
                print(f'Failed to process image: {img_path}')

    # Convert lists to NumPy arrays
    images = np.array(images)
    labels = np.array(labels)

    return images, labels

# Preprocess the dataset
images, labels = preprocess_images(data_dir, categories, target_size)

# Encode the labels as integers
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

# Create an SVM classifier model (RBF kernel by default)
svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')  # You can experiment with 'linear', 'poly', or 'rbf'

# Train the SVM model
svm_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Test Accuracy: {accuracy:.4f}')

# Detailed classification report
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

"""**different ml algorithms**"""

!pip install scikeras
import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from keras.models import Sequential
from keras.layers import Dense
# Import KerasClassifier from scikeras.wrappers
from scikeras.wrappers import KerasClassifier
import matplotlib.pyplot as plt
import seaborn as sns

# Set dataset directory and categories
data_dir = '/content/drive/MyDrive/Pomegranate Diseases Dataset/Pomegranate Diseases Dataset'  # Path to your dataset
categories = ['Healthy', 'Anthracnose', 'Bacterial_Blight', 'Cercospora', 'Alternaria']
target_size = (128, 128)  # Resize images to a uniform size

# Function to preprocess and flatten images
def preprocess_images(data_dir, categories, target_size):
    images = []
    labels = []
    for category in categories:
        category_path = os.path.join(data_dir, category)
        label = category  # Use category names as labels
        for img_name in os.listdir(category_path):
            img_path = os.path.join(category_path, img_name)
            image = cv2.imread(img_path)
            if image is not None:
                image = cv2.resize(image, target_size)
                image = image.flatten()
                image = image.astype('float32') / 255.0
                images.append(image)
                labels.append(label)
            else:
                print(f'Failed to process image: {img_path}')
    images = np.array(images)
    labels = np.array(labels)
    return images, labels

# Preprocess the dataset
images, labels = preprocess_images(data_dir, categories, target_size)

# Encode the labels as integers
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

# Define classifiers
classifiers = {
    'SVM': SVC(kernel='rbf', C=1.0, gamma='scale'),
    'k-NN': KNeighborsClassifier(n_neighbors=5),
    '1-NN': KNeighborsClassifier(n_neighbors=1),
    'Random Forest': RandomForestClassifier(n_estimators=100),
}

def create_ann():
    model = Sequential()
    model.add(Dense(64, input_dim=images.shape[1], activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(len(np.unique(labels)), activation='softmax'))
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

classifiers['ANN'] = KerasClassifier(build_fn=create_ann, epochs=10, batch_size=10, verbose=0)

# Train, predict and evaluate each classifier
results = {}

for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)

    results[name] = {
        'accuracy': accuracy,
        'conf_matrix': conf_matrix,
        'classification_report': classification_report(y_test, y_pred, target_names=label_encoder.classes_)
    }

    print(f'{name} Classifier:')
    print(f'Accuracy: {accuracy * 100:.2f}%')
    print('Confusion Matrix:')
    print(conf_matrix)
    print('Classification Report:')
    print(results[name]['classification_report'])
    print('\n')

# Example feedforward neural network
model = Sequential()
model.add(Dense(64, input_dim=images.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(len(np.unique(labels)), activation='softmax'))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0)
y_pred_nn = np.argmax(model.predict(X_test), axis=-1)
accuracy_nn = accuracy_score(y_test, y_pred_nn)
conf_matrix_nn = confusion_matrix(y_test, y_pred_nn)

print('Feedforward Neural Network Classifier:')
print(f'Accuracy: {accuracy_nn * 100:.2f}%')
print('Confusion Matrix:')
print(conf_matrix_nn)
print('Classification Report:')
print(classification_report(y_test, y_pred_nn, target_names=label_encoder.classes_))

# Add feedforward neural network to results
results['Feedforward Neural Network'] = {
    'accuracy': accuracy_nn,
    'conf_matrix': conf_matrix_nn,
    'classification_report': classification_report(y_test, y_pred_nn, target_names=label_encoder.classes_)
}

# Plot test accuracy graph
classifier_names = list(results.keys())
accuracies = [results[name]['accuracy'] for name in classifier_names]

plt.figure(figsize=(10, 6))
plt.bar(classifier_names, accuracies, color='skyblue')
plt.xlabel('Classifiers')
plt.ylabel('Test Accuracy')
plt.title('Test Accuracy of Different Classifiers')
plt.ylim(0, 1)  # Accuracy values range from 0 to 1
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

